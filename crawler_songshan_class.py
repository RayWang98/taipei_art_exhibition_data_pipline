# ====================================================================
# I. æ ¸å¿ƒ AI æœå‹™ (Gemini/RAG) & OCR
# ====================================================================
import cv2                        # è™•ç†åœ–ç‰‡ (OCR)
import json                       # è™•ç† JSON æ ¼å¼
from google import genai          # Gemini API
from google.genai import types    # Gemini çµæ§‹åŒ–è¼¸å‡º Schema
import easyocr                    # OCR åœ–ç‰‡æ–‡å­—è­˜åˆ¥
from google.genai.errors import APIError # è™•ç† Gemini API éŒ¯èª¤
import googlemaps
from googlemaps.exceptions import ApiError, Timeout 

# ====================================================================
# II. ç¶²è·¯è«‹æ±‚ (Web/HTTP) èˆ‡è§£æ
# ====================================================================
from bs4 import BeautifulSoup as bs           # HTML è§£æ
import requests as req                        # HTTP è«‹æ±‚
from urllib.parse import urljoin, urlparse    # URL çµ„åˆ

# ====================================================================
# III. æª”æ¡ˆ/ç³»çµ±èˆ‡ç’°å¢ƒè®Šæ•¸ç®¡ç†
# ====================================================================
import os                         # è®€å–ç’°å¢ƒè®Šæ•¸
from pathlib import Path as pp    # æª”æ¡ˆè·¯å¾‘æ“ä½œ
import time                       # åŸ·è¡Œå»¶é²
from dotenv import load_dotenv    # ç’°å¢ƒè®Šæ•¸

# ====================================================================
# IV. è³‡æ–™è™•ç†ã€æ™‚é–“è™•ç†èˆ‡éš¨æ©Ÿæ€§è®Šæ•¸
# ====================================================================
import random as rd               # éš¨æ©Ÿå»¶é²æ™‚é–“
from datetime import datetime     # è™•ç†æ—¥æœŸèˆ‡æ™‚é–“
import pandas as pd               # è³‡æ–™è™•ç†è½‰æ›
import numpy as np                # è³‡æ–™è™•ç†è½‰æ›
from typing import Optional, List, Dict, Any # è³‡æ–™æ ¼å¼å®šç¾©
from dataclasses import dataclass, field

@dataclass
class exhibition_data:
    # æ–‡å­—çˆ¬èŸ²è³‡è¨Š
    hallname : str = 'æ¾å±±æ–‡å‰µåœ’å€'
    space : str = '' # å±•é¤¨çš„å ´åœ°ä½ç½®
    start_date : str = '' # é–‹å§‹æ—¥æœŸ
    end_date : str = '' # çµæŸæ—¥æœŸ
    title : str = '' # å±•è¦½åç¨±
    overview : str = '' # å±•è¦½é‡é»æ•˜è¿°
    pageurl : str = '' # å±•è¦½å…§å®¹ç¶²å€
    pageimgurl : List[str] = field(default_factory = list) # çˆ¬èŸ²å–å¾—çš„åœ–ç‰‡ URL åˆ—è¡¨ï¼Œå„ç€è¦½é é¢å…§çš„æ¯ä¸€å¼µåœ–ç‰‡
    pagetext : str = ''     # ç¶²é åŠ OCR æ•´åˆå¾Œçš„æ–‡æœ¬ # å±•è¦½å…§å®¹æ•˜è¿°
    big_img_url : str = '' # é¦–é ä¸Šé¢çš„å±•ç¤ºåœ–ï¼Œå¾ŒçºŒç”¨é€™å€‹!!!!!
    big_img_bytes : Optional[bytes] = None     # å­˜æ”¾åœ–ç‰‡äºŒé€²åˆ¶å…§å®¹ (åœ¨ ETL æµç¨‹ä¸­å¯èƒ½éœ€è¦æš«å­˜) # é€™è£¡æ”¾åœ–ç‰‡çš„äºŒé€²åˆ¶å…§å®¹ï¼Œç­‰ç­‰æ¯å€‹éƒ½æ”¾é€²å»è¾¨è­˜å…§å®¹ï¼Œå–å‡ºæœ‰ç”¨è³‡è¨Š
    # åœ–ç‰‡åŠAIæ•´åˆå¾Œè³‡è¨Š
    visit_time_interval : str = 'ç„¡è³‡è¨Š'
    price : str = 'ç„¡è³‡è¨Š'
    note : str = 'ç„¡è³‡è¨Š'
    url : List[str] = field(default_factory = list) # è¨­å®šä¸å¯è®Šå‹•çš„é è¨­å€¼ï¼Œç‰¹åˆ¥æ˜¯ç•¶æ¬„ä½çš„é è¨­å€¼æ˜¯å¯è®Šå®¹å™¨
    lat : Optional[float] = None # ç·¯åº¦
    lon : Optional[float] = None # ç¶“åº¦

    # ======================================
    # field(default_factory=list) çš„ä½œç”¨æ˜¯å‘Šè¨´ Pythonï¼š
    # >>ã€Œæ¯æ¬¡å»ºç«‹æ–°çš„ MutableContainerExample å¯¦ä¾‹æ™‚ï¼Œä¸è¦å…±äº«èˆŠçš„ list ç‰©ä»¶ï¼Œè«‹å‘¼å« list() é€™å€‹å·¥å» å‡½å¼ï¼Œ
    # >> ç‚ºé€™å€‹æ–°çš„å¯¦ä¾‹å»ºç«‹ä¸€å€‹å…¨æ–°çš„ã€ç¨ç«‹çš„ list ç‰©ä»¶ã€‚ã€
    # ======================================
# å®šç¾© AI çµæ§‹åŒ–è¼¸å‡ºçš„æ•¸æ“šçµæ§‹ (èˆ‡ Gemini Schema ä¿æŒä¸€è‡´)
# é›–ç„¶æˆ‘å€‘å¾ JSON è¼‰å…¥ï¼Œä½†é€™æä¾›äº†ä¸€å€‹æ¸…æ™°çš„ç›®æ¨™çµæ§‹

@dataclass
class GeminiExtractedData:
    title : str # å±•è¦½åç¨±
    visit_time_interval : str # åƒè§€æ™‚é–“
    price : str # ç¥¨åƒ¹
    note : str = 'ç„¡è³‡è¨Š' # ç¯€å–å‡ºä¾†çš„é¡å¤–è³‡è¨Š
    url : List[str] = field(default_factory=list) # å®˜ç¶² æ´»å‹•ç›¸é—œçš„æ‰€æœ‰é‡è¦ç¶²å€(å®˜ç¶²ã€FBã€è³¼ç¥¨é€£çµç­‰)ã€‚

class EmptyResponseError(Exception):
    '''è‡ªå®šç¾©éŒ¯èª¤ï¼šç•¶ API å›å‚³ç©ºçš„æ–‡å­—å…§å®¹æ™‚æ‹‹å‡ºã€‚'''
    pass

class ExhibitionETLPipeline:
    def __init__(self, default_addr : str = r'11072è‡ºåŒ—å¸‚ä¿¡ç¾©å€å…‰å¾©å—è·¯133è™Ÿ'):
        print('Info: åˆå§‹åŒ– ETL Pipeline...')
        # ç’°å¢ƒè®Šæ•¸èˆ‡è¨­å®š
        USER_AGENT = os.environ.get('USER_AGENT')
        CONNECTION = os.environ.get('CONNECTION', 'keep-alive')
        ACCEPT = os.environ.get('ACCEPT', '*/*')
        self.hd = {'user-agent': USER_AGENT, 'connection' : CONNECTION, 'accept' : ACCEPT} # ç€è¦½å™¨agentè¨­å®š
        self.GEMINI_KEY = os.getenv('GEMINI_API_KEY') # AI APIKEY
        self.urlpath = r'https://www.songshanculturalpark.org/exhibition' # çˆ¬å–é¦–é 
        self.imgpath = r'https://www.songshanculturalpark.org/gallery/' # ç¶²é çš„åŸºæº–ç¶²å€ï¼Œç”¨ä¾†è™•ç†ç›¸å°è·¯å¾‘
        self.MAX_RETRIES = 5 # AIè¾¨è­˜æ™‚æœ€å¤§è™•ç†æ¬¡æ•¸è¨­å®š
        self.INITIAL_DELAY = 10 # å‰›é–‹å§‹çš„ç­‰å¾…ç§’æ•¸
        self.MAPS_KEY = os.getenv('GOOGLE_MAPS_API_KEY')
        self.addr = default_addr
        
        # åˆå§‹åŒ–å¤–éƒ¨æœå‹™
        # ======================== Gemini ========================
        if self.GEMINI_KEY:
            self.client = genai.Client(api_key=self.GEMINI_KEY)
            print('Gemini åˆå§‹åŒ–æˆåŠŸ')
        else:
            self.client = None
            print('Gemini åˆå§‹åŒ–å¤±æ•—')   

        # ======================== OCR Model ========================
        try:
            self.ocr_reader = easyocr.Reader(['ch_tra', 'en'])
            print('Info: EasyOCR æ¨¡å‹è¼‰å…¥æˆåŠŸã€‚')
        except Exception as e:
            print(f'Error: EasyOCR æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}')
            self.ocr_reader = None
        
        # ======================== GOOGLE MAPS ========================
        if self.MAPS_KEY:
            self.gmaps = googlemaps.Client(key=self.MAPS_KEY)
            print('google mapåˆå§‹åŒ–æˆåŠŸ')
        else:
            self.gmaps = None
            print('google mapåˆå§‹åŒ–å¤±æ•—')


    # 2. Worker Method =========================================================================
    def _download_img(self, img_src: str) -> bytes | None:
        img_url = urljoin(self.imgpath, img_src)
        try:
            resp = req.get(img_url, headers = self.hd, timeout = 10)
            resp.raise_for_status()  # å¦‚æœç‹€æ…‹ç¢¼ä¸æ˜¯ 200ï¼Œå°±ç›´æ¥ä¸Ÿå‡ºéŒ¯èª¤
            # è¿”å›åœ–ç‰‡çš„äºŒé€²åˆ¶å…§å®¹
            return resp.content  # æˆåŠŸæ™‚å›å‚³åœ–ç‰‡å­˜æ”¾çš„å®Œæ•´è·¯å¾‘

        except Exception as e:
            # å¦‚æœä¸‹è¼‰å¤±æ•—ï¼Œå›å‚³è¨Šæ¯
            print(f'[{datetime.now()}] {img_url} -> {e}\n')
        return None  # å¤±æ•—å°±å›å‚³ None
    
    def _eocr_process(self, image_bytes: bytes) -> str:
        '''
        ä½¿ç”¨ EasyOCR è®€å–è¨˜æ†¶é«”ä¸­çš„åœ–ç‰‡bytesï¼Œä¸¦å°‡çµæœæ ¼å¼åŒ–ç‚ºæ˜“æ–¼ AI æå–çš„ç´”æ–‡å­—å­—ä¸²
        '''
        if not image_bytes or self.ocr_reader is None:
            return f'Error åœ–ç‰‡å…§å®¹ç‚ºç©ºæˆ– OCR è®€å–å™¨æœªåˆå§‹åŒ–'

        try:
            # 1. è®€å–åœ–ç‰‡
            nparr = np.frombuffer(image_bytes, np.uint8) # åœ–ç‰‡æª”æ¡ˆçš„åŸå§‹ä½å…ƒçµ„ï¼Œé€é np.frombuffer() è½‰æ›æˆäº† NumPy é™£åˆ—
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR) # ä½¿ç”¨ OpenCV å¾è¨˜æ†¶é«”ä¸­è§£ç¢¼åœ–ç‰‡ï¼›ä¸¦å‘Šè¨´ OpenCVæ‡‰è©²ä»¥å½©è‰² (Color) æ¨¡å¼è¼‰å…¥åœ–ç‰‡ã€‚å¦‚æœåœ–ç‰‡æ˜¯ç°éš (Grayscale)ï¼Œå®ƒæœƒè¢«è½‰æ›ç‚ºä¸‰é€šé“å½©è‰²ã€‚
            if image is None:
                return 'Error éŒ¯èª¤ï¼šç„¡æ³•è®€å–åœ–ç‰‡ï¼Œè«‹æª¢æŸ¥è¨˜æ†¶é«”å…§å„²å­˜ç‹€æ…‹ã€‚'
            h, w, _ = image.shape # åœ–ç‰‡shape:é«˜ã€å¯¬ã€é¡è‰²ï¼›ç¬¬ä¸‰è€…ç‚ºBGRï¼Œç¶­åº¦3ï¼Œä½†é€™è£¡ä¸éœ€è¦ä½¿ç”¨
            # 2. åŸ·è¡Œ OCR
            results = self.ocr_reader.readtext(image, detail = 1)

        except Exception as e:
            return f'Error EasyOCR æˆ– OpenCV ç™¼ç”ŸéŒ¯èª¤: {e}'

        # 2.1 **åˆ†å·¦å³å…©é‚Šå€å¡Š** çš„å‹•æ…‹åƒæ•¸è¨­å®š================================
        # è¨­ç½®ç‚ºåœ–ç‰‡é«˜åº¦çš„ 2%ã€‚å¦‚æœæ–‡å­—å¾ˆå°ï¼Œå¯èƒ½éœ€è¦é™ä½åˆ° 0.01ã€‚åˆ¤æ–·å…©å€‹æ–‡å­—å¡Šæ˜¯å¦å±¬æ–¼åŒä¸€è¡Œçš„ Y è»¸è·é›¢
        row_tolerance = h * 0.016

        # å¦‚æœåˆ†éš”ç·šä¸åœ¨ä¸­é–“ï¼Œä¾‹å¦‚å·¦æ¬„ä½” 60%ï¼Œå‰‡è¨­ç‚º 0.6ã€‚åˆ¤æ–·æ–‡å­—å¡Šå±¬æ–¼å·¦æ¬„é‚„æ˜¯å³æ¬„çš„åˆ†ç•Œç·š
        center_x_factor = 0.5 # ä¸­é–“åˆ†éš”ç·šåˆ¤æ–·
        center_x = w * center_x_factor

        processed_data = [] # ç”¨ä¾†å„²å­˜æ‰€æœ‰å·²ç¶“ç¢ºå®šç‚ºä¸€è¡Œçš„æ•¸æ“šçµæ§‹

        # æ ¹æ“š X åº§æ¨™åˆ†è¡Œä¸¦æ¨™è¨˜å·¦å³æ¬„ä½
        for bbox, text, conf in results: # åº§æ¨™é»(å…±æœ‰å››é»å·¦ä¸Š[0]ã€å³ä¸Š[1]ã€å³ä¸‹[2]ã€å·¦ä¸‹[3]é †æ™‚é‡)ã€æ–‡å­—å…§å®¹ã€ä¿¡å¿ƒç¨‹åº¦
            # å–å¾—é‚Šç•Œæ¡†çš„ä¸­å¿ƒé» Y å’Œ X åº§æ¨™ï¼Œä¸¦ä¸”æŠŠæ¯å€‹bboxå’Œtextéƒ½æ‹¿å‡ºä¾†åˆ¤æ–·
            y_center = (bbox[0][1] + bbox[2][1]) / 2 # åˆ¤æ–·è¾¨è­˜å€å¡Šçš„Yè»¸ä¸­å¿ƒé»
            x_center = (bbox[0][0] + bbox[1][0]) / 2 # åˆ¤æ–·è¾¨è­˜å€å¡Šçš„Xè»¸ä¸­å¿ƒé»

            # æ ¹æ“š X åº§æ¨™åˆ¤æ–·æ¬„ä½
            column = 'left' if x_center < center_x else 'right' # å¦‚æœè©²åˆ¤æ–·å€å¡Šï¼Œè½åœ¨ä¸­ç·šå·¦é‚Šï¼Œå‰‡ä»£è¡¨æ˜¯å·¦å´çš„å€å¡Šï¼Œåä¹‹äº¦ç„¶

            # åˆ¤æ–·æ˜¯å¦ç‚ºåŒä¸€è¡Œ
            merged = False # åˆä½µé–‹é—œ
            for item in processed_data:
                if abs(y_center - item['y']) < row_tolerance: # å¦‚æœYè»¸å’Œè©²è¼ªçš„å€å¡ŠYè»¸ä¸­å¿ƒå°æ–¼åˆ¤æ–·è·é›¢ï¼Œå‰‡åˆ¤å®šç‚ºåŒä¸€å¥è©±ï¼Œå¦‚æœæ˜¯åŒä¸€è¡Œï¼Œå°‡ç•¶å‰çš„æ–‡å­—å¡Šæ·»åŠ åˆ°å·²å­˜åœ¨çš„itemä¸­
                    item['texts'].append({'text': text, 'x': x_center, 'col': column, 'y' : y_center})
                    merged = True
                    break # æ‰¾åˆ°æ‡‰è©²æ”¾åˆ°å“ªä¸€è¡Œå¾Œï¼Œå‰‡è·³å‡ºæ­¤è¼ªå¾ªç’°

            if not merged: # å¦‚æœè¿´åœˆçµæŸéƒ½æ‰¾ä¸åˆ°åŒ¹é…çš„è¡Œï¼Œå‰‡å‰µå»ºä¸€å€‹æ–°çš„è¡Œ
                processed_data.append({
                    'y': y_center,
                    'texts': [{'text': text, 'x': x_center, 'col': column, 'y' : y_center}]
                }) # ç´€éŒ„å€å¡ŠYè»¸ä¸­å¿ƒé»ã€è¾¨è­˜å‡ºä¾†çš„æ–‡å­—å…§å®¹ã€å€å¡ŠXè»¸ä¸­å¿ƒé»ã€åˆ¤æ–·å¾Œæ˜¯lefté‚„æ˜¯right

        # æ’åºèˆ‡æ ¼å¼åŒ–è¼¸å‡º
        processed_data = sorted(processed_data, key = lambda r : r['y']) # å–å‡º yå€¼é€²è¡Œæ’åº

        left_column_output = ''
        right_column_output = ''

        for row in processed_data:
            # å°åŒä¸€è¡Œåˆ—çš„æ–‡å­—ï¼Œä¾ X åº§æ¨™æ’åºï¼Œåˆ¤å®šå®ƒå±¬æ–¼å“ªä¸€å€‹è¡Œ
            left_texts_raw = [t for t in row['texts'] if t['col'] == 'left']
            right_texts_raw = [t for t in row['texts'] if t['col'] == 'right']
            # å…ˆæŒ‰ X è»¸æ’åºï¼Œè‹¥ X ç›¸åŒï¼Œå‰‡ç”¨ Y è»¸ç¢ºä¿å‚ç›´é †åº
            sorted_left_texts = sorted(left_texts_raw, key=lambda t: (t['x'], t['y']))
            sorted_right_texts = sorted(right_texts_raw, key=lambda t: (t['x'], t['y']))

            # å»é™¤ç©ºç™½ï¼Œä¸¦è½‰ç‚ºlist
            left_texts = [t['text'] for t in sorted_left_texts if t['text'].strip() != '']
            right_texts = [t['text'] for t in sorted_right_texts if t['text'].strip() != '']

            # å°‡æ–‡å­—å„è‡ªä¸²æ¥èµ·ä¾†ï¼Œä¸¦åŠ ä¸Šæ›è¡Œç¬¦è™Ÿ
            if left_texts:
                left_column_output += ' '.join(left_texts) + '\n'
            if right_texts:
                right_column_output += ' '.join(right_texts) + '\n'

        # 2.2 **ä¸åˆ†é‚Š** çš„å‹•æ…‹åƒæ•¸è¨­å®š================================
        processed_data_unmerged = [] # ç”¨ä¾†å„²å­˜æ‰€æœ‰å·²ç¶“ç¢ºå®šç‚ºä¸€è¡Œçš„æ•¸æ“šçµæ§‹
        column_output = ''
        # è¨­ç½®ç‚ºåœ–ç‰‡é«˜åº¦çš„ 1.1%ã€‚å¦‚æœæ–‡å­—å¾ˆå°ï¼Œå¯èƒ½éœ€è¦é™ä½åˆ° 0.01ã€‚åˆ¤æ–·å…©å€‹æ–‡å­—å¡Šæ˜¯å¦å±¬æ–¼åŒä¸€è¡Œçš„ Y è»¸è·é›¢
        row_tolerance_unmerged = h * 0.011

        for bbox, text, conf in results: # åº§æ¨™é»(å…±æœ‰å››é»å·¦ä¸Š[0]ã€å³ä¸Š[1]ã€å³ä¸‹[2]ã€å·¦ä¸‹[3]é †æ™‚é‡)ã€æ–‡å­—å…§å®¹ã€ä¿¡å¿ƒç¨‹åº¦
            # å–å¾—é‚Šç•Œæ¡†çš„ä¸­å¿ƒé» Y å’Œ X åº§æ¨™ï¼Œä¸¦ä¸”æŠŠæ¯å€‹bboxå’Œtextéƒ½æ‹¿å‡ºä¾†åˆ¤æ–·
            y_center = (bbox[0][1] + bbox[2][1]) / 2 # åˆ¤æ–·è¾¨è­˜å€å¡Šçš„Yè»¸ä¸­å¿ƒé»
            x_center = (bbox[0][0] + bbox[1][0]) / 2 # åˆ¤æ–·è¾¨è­˜å€å¡Šçš„Xè»¸ä¸­å¿ƒé»

            column = 'center'

            # åˆ¤æ–·æ˜¯å¦ç‚ºåŒä¸€çµ„
            merged = False # åˆä½µé–‹é—œ
            for item in processed_data_unmerged:
                if abs(y_center - item['y']) < row_tolerance_unmerged: # å¦‚æœYè»¸å’Œè©²è¼ªçš„å€å¡ŠYè»¸ä¸­å¿ƒå°æ–¼åˆ¤æ–·è·é›¢ï¼Œå‰‡åˆ¤å®šç‚ºåŒä¸€å¥è©±ï¼Œå¦‚æœæ˜¯åŒä¸€è¡Œï¼Œå°‡ç•¶å‰çš„æ–‡å­—å¡Šæ·»åŠ åˆ°å·²å­˜åœ¨çš„itemä¸­
                    item['texts'].append({'text': text, 'x': x_center, 'col': column, 'y' : y_center})
                    merged = True
                    break # æ‰¾åˆ°æ‡‰è©²æ”¾åˆ°å“ªä¸€è¡Œå¾Œï¼Œå‰‡è·³å‡ºæ­¤è¼ªå¾ªç’°

            if not merged: # å¦‚æœè¿´åœˆçµæŸéƒ½æ‰¾ä¸åˆ°åŒ¹é…çš„è¡Œï¼Œå‰‡å‰µå»ºä¸€å€‹æ–°çš„è¡Œ
                processed_data_unmerged.append({
                    'y': y_center,
                    'texts': [{'text': text, 'x': x_center, 'col': column, 'y' : y_center}]
                }) # ç´€éŒ„å€å¡ŠYè»¸ä¸­å¿ƒé»
        # æ’åºèˆ‡æ ¼å¼åŒ–è¼¸å‡º
        processed_data_unmerged = sorted(processed_data_unmerged, key = lambda r : r['y']) # å–å‡º yå€¼é€²è¡Œæ’åº

        for row in processed_data_unmerged:
            texts_raw = [t for t in row['texts']] # æ”¾åˆ°listä¸­
            sorted_texts = sorted(texts_raw, key=lambda t: (t['x'], t['y'])) # æ’åºï¼Œxä½ç½®å…ˆï¼Œyä½ç½®å¾Œ

            # å°‡æ–‡å­—å„è‡ªä¸²æ¥èµ·ä¾†ï¼Œä¸¦åŠ ä¸Šæ›è¡Œç¬¦è™Ÿ
            sorted_texts_list = [t['text'] for t in sorted_texts if t['text'].strip() != '']
            if sorted_texts_list:
                column_output += ' '.join(sorted_texts_list) + '\n'

        # æœ€çµ‚è¼¸å‡ºçµ¦ AI çš„æ ¼å¼
        ocr_text_output = '--- OCR åœ–ç‰‡å…§å®¹æå–çµæœï¼ˆå·¦å³åˆ†æ¬„ï¼‰---\n'
        ocr_text_output += '\n=== å·¦æ¬„å…§å®¹ (å„ªå…ˆé–±è®€) ===\n' + left_column_output.strip()
        ocr_text_output += '\n\n=== å³æ¬„å…§å®¹ (æ¬¡è¦é–±è®€) ===\n' + right_column_output.strip()
        ocr_text_output += '\n\n\n=== ä¸åˆ†æ¬„å…§å®¹ (å¦å¤–ç‰ˆæœ¬) ===\n' + column_output.strip()
        ocr_text_output += '\n--------------------------------------'

        return ocr_text_output    

    def _get_exhibition_urls(self) -> List[str]: # ç”¨ä¾†çˆ¬è¦æŠ“çš„ç¶²é é€£çµ
        res = req.get(self.urlpath, headers = self.hd, timeout = 12)
        soup = bs(res.text, 'html.parser')
        # å±•è¦½é é¢é€£çµ
        infourl = [urljoin(self.urlpath, i.find('a', class_='btn')['href']) for i in soup.find_all('span', class_='row_rt')] # ç­‰ç­‰è¦çˆ¬çš„æ‰€æœ‰ç¶²é é€£çµ
        return infourl

    def _extract_base_info(self, infourls : List[str]) -> List[exhibition_data]: # ç”¨ä¾†æŠ“å–æ¯å€‹é€£çµçš„ç´°é …
        extracted_data : List[exhibition_data] = []
        for ccnt, i in enumerate(infourls):
            resi = req.get(i, self.hd) # ä½¿ç”¨ self.hd
            soup = bs(resi.text, 'html.parser')
            
            # ä½¿ç”¨ exhibition_data æ›¿ä»£ infolist å­—å…¸
            data = exhibition_data() 
            data.pageurl = i
            data.title = soup.select_one('div.news_inner p.inner_title').get_text(strip = True)
            date_range = soup.select_one('div.under > p.montsrt').get_text(strip = True).split(' - ')
            data.start_date = date_range[0]
            data.end_date = date_range[1]
            data.overview = soup.select_one('article.big_article').get_text(strip = True) # ç€è¦½é é¢çš„ç°¡çŸ­ä»‹ç´¹
            
            # åœ–ç‰‡ URL è™•ç†ï¼šé€™è£¡åªå­˜ big_img çš„ URLï¼Œå¯¦éš›åœ–ç‰‡ä¸‹è¼‰æœƒåœ¨å¾ŒçºŒæ­¥é©Ÿ
            big_img_src = soup.select_one('img.big_img').get('src') # æŠ“å–å±•è¦½å¤§åœ–
            data.big_img_url = urljoin(self.imgpath, big_img_src) # å°‡åœ–ç‰‡URLå­˜å…¥URLæ¬„ä½
            data.space = soup.select_one('p.place').get_text(strip = True)
            data.pagetext = soup.select_one('section').get_text('\n', strip = True) # é€²å…¥è©²å±•è¦½å¾Œçš„ç¶²é å…§æ–‡
            data.pageimgurl = [imgtag.get('src') for imgtag in soup.select('section img')]

            print(f'[{ccnt + 1}/{len(infourls)}] æå–åŸºç¤è³‡è¨Š: {data.title}') 
            extracted_data.append(data)
            time.sleep(rd.randint(1, 15))
            
        return extracted_data
    
    def _extract_with_gemini(self, anns: List[exhibition_data]) -> List[exhibition_data]: # ç”¨ä¾†è·‘google gemeniçš„
        
        # æç¤ºè©èˆ‡ Schema å®šç¾© (èˆ‡æ‚¨åŸç¨‹å¼ç¢¼ V. ä¿æŒä¸€è‡´ï¼Œåªæ˜¯ç§»å‹•åˆ°é€™è£¡)
        extraction_schema = types.Schema(
        type = types.Type.OBJECT, # ä½¿ç”¨ OBJECT ä½œç‚ºå–®ä¸€æ´»å‹•çš„å®¹å™¨
            properties = {
                'title': types.Schema(type = types.Type.STRING, description = 'æ´»å‹•çš„ä¸»è¦åç¨±æˆ–æ¨™é¡Œã€‚'),
                'visit_time_interval': types.Schema(type = types.Type.STRING, description = 'æ´»å‹•çš„é–‹æ”¾æˆ–ç‡Ÿæ¥­æ™‚é–“ï¼Œéœ€åŒ…å«ä¸åŒæ—¥æœŸçš„è®ŠåŒ–å’Œæœ€å¾Œå…¥å ´æ™‚é–“çš„èªªæ˜ï¼Œè«‹çµ±ä¸€ä½¿ç”¨ 24 å°æ™‚åˆ¶ï¼Œä¾‹å¦‚ **10:00 - 17:00**ã€‚'),
                'price': types.Schema(type = types.Type.STRING, description = 'ç¥¨å‹™æˆ–å…¥å ´è³‡è¨Šï¼Œå¦‚æœå…è²»è«‹å¯« **å…è²»å…¥å ´**ã€‚'),
                'note': types.Schema(type = types.Type.STRING, description = 'å¦‚æœå±•è¦½æ˜¯å¤šå€‹é …ç›®çµ„æˆï¼Œå‰‡å°‡å„è‡ªçš„è³‡è¨Šå­˜æ”¾æ–¼æ­¤ï¼Œéœ€è¦çš„å…§å®¹ç‚º**åç¨±(title)**ã€**æ—¥æœŸ(date)**ã€**æ™‚é–“(visit_time_interval)**ã€**ç¥¨åƒ¹(price)**'),
                'url': types.Schema(
                    type = types.Type.ARRAY,
                    description = 'æ´»å‹•ç›¸é—œçš„æ‰€æœ‰é‡è¦ç¶²å€(å®˜ç¶²ã€FBã€è³¼ç¥¨é€£çµç­‰)ã€‚',
                    items = types.Schema(type = types.Type.STRING, description = 'å®Œæ•´çš„ URLã€‚') # URL å­—ä¸²çš„é™£åˆ—
                )
            },
        required = ['title', 'visit_time_interval', 'price'] # å¿…è¦æ¬„ä½
        )

        # æç¤ºè©å·¥ç¨‹
        base_prompt = r'''
        æ‚¨æ˜¯ä¸€ä½å°ˆæ¥­çš„æ•¸æ“šåˆ†æå¸«å’Œå±•è¦½ç­–å±•äººå“¡ã€‚æ‚¨çš„ä»»å‹™æ˜¯å¾æä¾›çš„æ–‡æœ¬å…§å®¹ä¸­ï¼Œè­˜åˆ¥ä¸¦åš´æ ¼æå–å–®ä¸€æ´»å‹•çš„è³‡è¨Šã€‚
        è«‹åš´æ ¼éµå®ˆä»¥ä¸‹è¦å‰‡ï¼š

        1.  **è¼¸å‡ºæ ¼å¼ï¼š** å¿…é ˆå°‡æå–çš„çµæœå°è£ç‚ºå–®ä¸€å€‹ JSON ç‰©ä»¶ï¼Œä¸¦**åš´æ ¼**éµå¾ªæˆ‘æŒ‡å®šçš„ JSON Schema æ ¼å¼ã€‚è«‹åªè¿”å› JSON æ ¼å¼çš„å…§å®¹ï¼Œä¸è¦æœ‰ä»»ä½•å¤šé¤˜çš„è§£é‡‹æˆ–æ–‡å­—ã€‚
        2.  **æå–ç›®æ¨™ï¼š** å„ªå…ˆæå–ç•¶å‰æ´»å‹•é é¢**æœ€ç›¸é—œ**çš„æ´»å‹•è³‡è¨Šã€‚
        3.  **æ´»å‹•åˆ—è¡¨è™•ç†ï¼š** å¦‚æœæ–‡æœ¬å…§å®¹ä¸­å‡ºç¾é¡ä¼¼**ã€Œæ¾å±±æ–‡å‰µåœ’å€å…¨æ”»ç•¥ã€**æˆ–åŒ…å«å¤šå€‹ä¸¦åˆ—æ´»å‹•åˆ—è¡¨çš„å…§å®¹ï¼Œè«‹å°‡**æ‰€æœ‰é€™äº›é¡å¤–æ´»å‹•**çš„è³‡è¨Šï¼Œä»¥**ã€Œæ´»å‹•åç¨±: æ—¥æœŸå€é–“, æ™‚é–“, ç¥¨åƒ¹ã€**çš„æ ¼å¼ï¼Œä½¿ç”¨ Markdown åˆ—é»æ–¹å¼æ•´ç†ï¼Œä¸¦æ”¾å…¥ **note** æ¬„ä½ä¸­ã€‚
        4.  **æ´»å‹•ç´°ç¯€è¦æ±‚ï¼š** æ•´ç†æ”¾å…¥ note æ¬„ä½çš„å…§å®¹éœ€åŒ…æ‹¬ï¼š**åç¨±**ã€**æ´»å‹•æ—¥æœŸå€é–“**ã€**ç‡Ÿæ¥­æ™‚é–“**ã€**ç¥¨åƒ¹**ã€‚
        5.  **RAG åƒè€ƒï¼š** æˆ‘æœƒä¸€ä½µçµ¦ä½ è©²å±•è¦½æå ±çš„ç°¡å–®è³‡è¨Šï¼Œä½ å¯ä»¥ç•¶ä½œåƒè€ƒé—œéµå­—ï¼Œæ”¾åœ¨æœ€å¾Œä¸¦ç”¨**{}**åŒ…èµ·ä¾†ã€‚
        6.  **æ™‚é–“æ ¼å¼ï¼š** ç‡Ÿæ¥­æ™‚é–“è«‹çµ±ä¸€ä½¿ç”¨ 24 å°æ™‚åˆ¶ï¼Œä¾‹å¦‚ **10:00 - 17:00**ã€‚

        ä»¥ä¸‹æ˜¯å¾…åˆ†æçš„æ´»å‹•æ–‡æœ¬ï¼š
        '''

        # è«‹æ¨¡å‹å†æ€è€ƒç”¨
        CORRECTION_PROMPT = '''
        \n[!!!] è­¦å‘Šï¼šæ‚¨ä¸Šä¸€æ¬¡çš„è¼¸å‡ºç„¡æ³•è¢«è§£æç‚ºæœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚
        è«‹æ‚¨**åš´æ ¼**é‡æ–°æª¢æŸ¥æ‚¨çš„è¼¸å‡ºå…§å®¹ï¼Œä¸¦ç¢ºä¿å®ƒæ˜¯ä¸€å€‹**ç´”æ·¨ã€å®Œæ•´ä¸”ç¬¦åˆ JSON è¦ç¯„**çš„ JSON å­—ä¸²
        (æœ‰æ²’æœ‰å¯èƒ½æ˜¯å°‘äº†ä¸Šä¸‹ä¸­æ‹¬å¼§æˆ–æ˜¯é€—é»è€Œå·²ï¼Œè«‹æ‚¨æ³¨æ„é€™é»)ï¼Œè«‹ä¸è¦åŒ…å«ä»»ä½•é¡å¤–çš„è§£é‡‹æ€§æ–‡å­—æˆ–å¼•è¨€ã€‚è¬è¬ï¼'''
        cantcatch = []

        # æ–‡æœ¬åˆ†æè¿´åœˆ (ä½¿ç”¨ self.client, self.MAX_RETRIES, self.INITIAL_DELAY)
        for item in anns:
            current_delay = self.INITIAL_DELAY
            text_content = item.pagetext 
            curt_name = item.title 

            # æç¤ºè©å¤–ï¼Œé™„ä¸Šåˆ—è¡¨ä¸Šçš„åŸºç¤è³‡è¨Šç•¶ä½œåˆ¤æ–·ä¾æ“š å…§éƒ¨RAGå·¥ç¨‹
            full_prompt = (base_prompt +
                           text_content +
                           # ä½¿ç”¨ dataclass å±¬æ€§ (item.title, item.strt_date ç­‰)
                           'ï¼Œé€™å€‹æ˜¯å±•è¦½è³‡è¨Š: {åç¨±:' + f"{item.title}ã€é–‹å§‹æ™‚é–“:{item.start_date}ã€çµæŸæ™‚é–“:{item.end_date}ã€å±•è¦½èªªæ˜:{item.overview}ã€åœ°é»{item.space}" + '}')

            for attempt in range(self.MAX_RETRIES): 
                try:
                    print(f'Info : é–‹å§‹å˜—è©¦æå–ã€Œ{curt_name}ã€æ´»å‹•è³‡è¨Š (ç¬¬ {attempt + 1}/{self.MAX_RETRIES} æ¬¡)')

                    response = self.client.models.generate_content(
                        model = 'gemini-2.5-flash-lite', 
                        contents = full_prompt, 
                        config=types.GenerateContentConfig( # è¨­å®šæ¨¡å‹å¦‚ä½•å›æ‡‰ï¼ŒåŒ…æ‹¬è¼¸å‡ºæ ¼å¼ã€é™åˆ¶å’Œå‰µé€ æ€§ç¨‹åº¦ç­‰
                            response_mime_type = 'application/json', # è¿”å›jsonæ ¼å¼è³‡æ–™
                            response_schema = extraction_schema, # å›æ‡‰çš„æ ¼å¼æŒ‰ç…§å‰é¢å®šç¾©çš„è¼¸å‡º
                            max_output_tokens = 1024, # é™åˆ¶å›å‚³çš„tokenæ•¸é‡ï¼Œç´„3-4å€‹è‹±æ–‡å­—æ¯æˆ–åŠå€‹ä¸­æ–‡å­—ç­‰æ–¼1å€‹token
                            temperature = 0.2 # æ„ˆä½çš„å€¼ä»£è¡¨æ¨¡å‹çš„å›ç­”æ›´å…·æ±ºå®šæ€§ã€æº–ç¢ºå’Œå¯é æ¸¬ï¼Œé©åˆéœ€è¦åš´æ ¼æ•¸æ“šæå–å’Œéµå¾ªæ ¼å¼çš„ä»»å‹™ã€‚è¼ƒé«˜çš„å€¼å‰‡é©ç”¨æ–¼å¯«ä½œã€å‰µæ„æˆ–é ­è…¦é¢¨æš´ã€‚
                        )
                    )
                    # å¢åŠ ä¸€é …æª¢æŸ¥ï¼šç¢ºä¿ response.text æ˜¯å€‹å­—ä¸²
                    if response is None or response.text is None:
                        raise EmptyResponseError(f'Error : API è¿”å›äº†ç©ºçš„æ–‡å­—å…§å®¹ã€‚')
                    
                    # å¦‚æœæˆåŠŸï¼Œè·³å‡ºé‡è©¦å¾ªç’° ==================================================== åˆ°é€™æ­¥ä»£è¡¨æœ‰æŠ“åˆ°è³‡æ–™
                    extracted_json = json.loads(response.text)  # dtype dict
                    
                    # å°‡çµæœå¾ JSON å­—å…¸å¯«å…¥ ExhibitionData çš„æ¬„ä½ä¸­
                    item.visit_time_interval = extracted_json.get('visit_time_interval', 'ç„¡è³‡è¨Š')
                    item.price = extracted_json.get('price', 'ç„¡è³‡è¨Š')
                    item.note = extracted_json.get('note', 'ç„¡è³‡è¨Š')
                    item.url = extracted_json.get('url', []) # url æ˜¯ List[str]

                    print(f'Successed : ã€Œ{curt_name}ã€æˆåŠŸæå–ï¼š{item.title}')
                    time.sleep(rd.randint(5, 15))
                    break
                    
                except (json.JSONDecodeError, EmptyResponseError) as e:
                    # ... éŒ¯èª¤è™•ç†é‚è¼¯ (ä¿æŒä¸è®Š) ...
                    # é€™è£¡çœç•¥éŒ¯èª¤è™•ç†ç´°ç¯€ï¼Œä½†é‚è¼¯èˆ‡æ‚¨åŸå…ˆç¨‹å¼ç¢¼ä¸€è‡´
                    if attempt < self.MAX_RETRIES - 1:
                        print(f"Waring : è­¦å‘Šï¼š=== ã€Œ{curt_name}ã€ === æ¨¡å‹æœªè¿”å›æœ‰æ•ˆ JSON (éŒ¯èª¤ï¼š{e})ã€‚é€™æ¬¡å–å¾—çš„å…§å®¹æ˜¯é€™äº›  {response.text}")
                        print(f'Action : è¦æ±‚æ¨¡å‹è‡ªæˆ‘ä¿®æ­£... ç­‰å¾… 5 ç§’å¾Œé‡è©¦ã€‚')
                        full_prompt += CORRECTION_PROMPT # å°‡ä¿®æ­£æŒ‡ä»¤é™„åŠ åˆ°æç¤ºè©ä¸­ï¼Œè«‹æ¨¡å‹é‡æ–°æ€è€ƒå¯èƒ½éŒ¯èª¤çš„åœ°æ–¹
                        time.sleep(5)
                        continue # ç¹¼çºŒä¸‹ä¸€æ¬¡é‡è©¦ (å¸¶è‘—ä¿®æ­£æç¤º)
                    else:
                        print(f'Fail : JSON æ ¼å¼éŒ¯èª¤å·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œè·³éæ­¤é …ç›®ã€‚')
                        cantcatch.append(curt_name) 
                        time.sleep(rd.randint(5, 15))
                        break

                except APIError as e:
                    if attempt < self.MAX_RETRIES - 1 and 'UNAVAILABLE' in str(e):
                        print(f'Error : ä¼ºæœå™¨éè¼‰ (503 éŒ¯èª¤)ã€‚ç­‰å¾… {current_delay} ç§’å¾Œé‡è©¦...')
                        time.sleep(current_delay)
                        current_delay *= 1.5
                        continue
                    else:
                        print(f'Fail : API å‘¼å«å¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œæˆ–ç™¼ç”Ÿä¸å¯æ¢å¾©éŒ¯èª¤: {e}')
                        cantcatch.append(curt_name)
                        time.sleep(rd.randint(5, 15))
                        break
                except Exception as e:
                    print(f'Error : ã€Œ{curt_name}ã€ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}')
                    cantcatch.append(curt_name)
                    time.sleep(rd.randint(5, 15))
                    break
            print('***************************')
        print(f'é€™äº›æ˜¯æ²’æœ‰æŠ“åˆ°çš„å±•è¦½: {cantcatch}')
        return anns
    
    def _transform_googlegeocoding(self, anns : List[exhibition_data]) -> List[exhibition_data]: # é€égoogleAPIå–å›åº§æ¨™
        if not self.gmaps:
            return anns
        print('Info : åŸ·è¡Œåœ°ç†ç·¨ç¢¼')

        for item in anns:
            full_addr = f'{self.addr} {item.space}'

            try:
                geocode_result = self.gmaps.geocode(full_addr) # type: ignore
                if geocode_result:
                    location = geocode_result[0]['geometry']['location']
                    item.lat = location['lat']
                    item.lon = location['lng']
                    print(f'Success: {item.title} -> ({item.lat}, {item.lon})')
                else:
                    print(f'Warning: æ‰¾ä¸åˆ°åœ°å€åº§æ¨™ -> {full_addr}')
                    item.lat = 0.0
                    item.lon = 0.0
            except Exception as e:
                print(f'Error: Geo-coding éŒ¯èª¤ ({item.title}): {e}')
            
            # é›–ç„¶ Google é€Ÿé™å¾ˆé«˜ï¼Œä½†ä¿æŒç¦®è²Œç¨å¾®åœé “
            time.sleep(0.1)
        return anns

    # 3. Execution Method (é€™æ˜¯æ ¸å¿ƒ ETL æµç¨‹ï¼Œå–ä»£ main() é‚è¼¯)
    def run_pipeline(self) -> pd.DataFrame:
        cwddate = datetime.strftime(datetime.today(), '%Y%m%d')
        print(f'=== é–‹å§‹ ETL æµç¨‹ï¼Œè³‡æ–™æ—¥æœŸ {cwddate} ===')

        # I. æå–ç¶²é è³‡è¨Š
        infourl = self._get_exhibition_urls() # å¦ä¸€å€‹æ–¹æ³•ä¾†å–å¾—ç¶²å€
        anns = self._extract_base_info(infourl)

        # II. åœ–ç‰‡ OCR è™•ç†
        # å‘¼å« self._download_img å’Œ self.eocr_process
        for item in anns:
            # é‡å°æ¯å€‹å±•è¦½ï¼Œéæ­·å…¶æ‰€æœ‰åœ–ç‰‡
            for idx, img_src in enumerate(item.pageimgurl):
                print(f'=== OCRè¾¨è­˜ä¸­ =========== {idx + 1} / {len(item.pageimgurl)} ==== {item.title} {img_src}')
                
                # ä½¿ç”¨ä¸‹è¼‰æ–¹æ³•ï¼Œä¸¦å‚³å…¥ self.imgpath å’Œ self.hd
                image_bytes = self._download_img(img_src)
                
                # ä½¿ç”¨ OCR è™•ç†æ–¹æ³•
                ocrtext = self._eocr_process(image_bytes) if image_bytes else None
                
                if ocrtext:
                    item.pagetext += ('\næ¥ä¸‹ä¾†æ˜¯åœ–ç‰‡OCRå…§å®¹æ–‡å­—ï¼Œ' + ocrtext) # å°‡OCRçµæœåŠ å…¥annså„²å­˜ä¸­äº†

        # III. AI çµæ§‹åŒ–æå– (Gemini)
        anns = self._extract_with_gemini(anns) 

        # IV. Geo-Coding è½‰æ›
        anns = self._transform_googlegeocoding(anns)
        
        # V. è¼‰å…¥ (Load) - æœªä¾†æ‚¨çš„ DTL å‡½å¼
        savedata = [item.__dict__ for item in anns] # å°‡ dataclass è½‰ç‚º dict åˆ—è¡¨ï¼Œä¸¦å‰µå»º DataFrame
        final_df = pd.DataFrame(savedata)
        
        return final_df


# 4. æª”æ¡ˆé‹è¡Œå…¥å£ (å–®ä¸€æª”æ¡ˆæ¸¬è©¦ç”¨)ï¼›åƒ…ä¿ç•™ä½œç‚ºå–®æ©Ÿç‰ˆæ¸¬è©¦ç”¨
# if __name__ == '__main__':
#     load_dotenv()
#     pipeline = ExhibitionETLPipeline()
#     final_df = pipeline.run_pipeline()


'''
å¥½çš„ï¼Œæˆ‘å·²ç¶“æ¥æ”¶ä¸¦è¨˜ä½äº†ç¬¬ä¸ƒå€‹æª”æ¡ˆçš„å…§å®¹ï¼šcrawler_songshan_class.pyã€‚

ğŸ¨ crawler_songshan_class.py ç¨‹å¼ç¢¼æ‘˜è¦ï¼š
é€™å€‹æª”æ¡ˆæ˜¯é‡å°ã€Œæ¾å±±æ–‡å‰µåœ’å€ã€çš„å°ˆé–€çˆ¬èŸ²ï¼Œå®ƒå¼•å…¥äº†æ›´è¤‡é›œçš„æ•¸æ“šæå–ç­–ç•¥ï¼šçµåˆäº†å‚³çµ±ç¶²é çˆ¬å–ã€åœ–ç‰‡ä¸‹è¼‰ã€OCR è­˜åˆ¥ï¼Œä»¥åŠæœ€çµ‚çš„ Gemini çµæ§‹åŒ–æå–ã€‚

è³‡æ–™æ¨¡å‹ï¼šå»¶çºŒ exhibition_data dataclassï¼Œå°‡ hallname è¨­ç‚º 'æ¾å±±æ–‡å‰µåœ’å€'ï¼Œä¸¦åŠ å…¥äº† pageimgurl (URL åˆ—è¡¨) å’Œ big_img_bytes (ç”¨æ–¼åœ–ç‰‡äºŒé€²åˆ¶å…§å®¹) æ¬„ä½ä¾†æ”¯æ´ OCR æµç¨‹ã€‚

æå–ç­–ç•¥ï¼ˆæ·±åº¦æ··åˆ E + Tï¼‰ï¼š

I. åŸºç¤æå– (_extract_base_info)ï¼š

å¾å±•è¦½åˆ—è¡¨é ç²å–æ‰€æœ‰å±•è¦½çš„è©³ç´° URLã€‚

é€²å…¥æ¯å€‹å±•è¦½é é¢ï¼Œç›´æ¥æå–å±•è¦½åç¨±ã€æ—¥æœŸç¯„åœ (start_date, end_date)ã€ç°¡è¦æ¦‚è¿°å’Œå ´åœ° (space)ã€‚

åœ–ç‰‡æº–å‚™ï¼šæå–è©³ç´°é é¢å…§æ‰€æœ‰åœ–ç‰‡çš„ URL (data.pageimgurl)ã€‚

II. åœ–ç‰‡èˆ‡ OCR è™•ç† (_download_img, _eocr_process)ï¼š

åœ–ç‰‡ä¸‹è¼‰ï¼š_download_img è² è²¬ä¸‹è¼‰åœ–ç‰‡çš„äºŒé€²åˆ¶å…§å®¹ã€‚

è¤‡é›œ OCR é‚è¼¯ï¼š_eocr_process æ˜¯ä¸€å€‹é«˜åº¦å®¢è£½åŒ–çš„ OCR å‡½æ•¸ï¼š

ä½¿ç”¨ EasyOCR å’Œ OpenCV è™•ç†åœ–ç‰‡çš„ bytes å…§å®¹ã€‚

å¯¦ä½œäº†æ ¹æ“šåœ–ç‰‡ X/Y åº§æ¨™é€²è¡Œçš„æ–‡å­—åˆ†è¡Œèˆ‡åˆ†æ¬„ä½ (å·¦å³æ¬„) é‚è¼¯ï¼Œèƒ½æ›´å¥½åœ°è™•ç†æµ·å ±æˆ–è¤‡é›œä½ˆå±€ä¸Šçš„æ–‡å­—ï¼Œä¸¦å°‡æ‰€æœ‰è­˜åˆ¥çµæœåˆä½µæˆä¸€å€‹ç´”æ–‡å­—å­—ä¸²ï¼Œé™„åŠ åˆ° item.pagetext ä¸­ã€‚

III. AI çµæ§‹åŒ–æå– (_extract_with_gemini)ï¼š

è¼¸å…¥ï¼šå°‡æ­¥é©Ÿ I æå–çš„ç´”æ–‡æœ¬åŠ ä¸Šæ­¥é©Ÿ II æå–çš„ OCR æ–‡æœ¬ï¼ˆitem.pagetextï¼‰ä½œç‚ºè¼¸å…¥ã€‚

ç›®æ¨™ï¼šå¾ç¶œåˆæ–‡æœ¬ä¸­æå–é›£ä»¥ç”¨çˆ¬èŸ²ç²¾ç¢ºå®šä½çš„è³‡è¨Šï¼ŒåŒ…æ‹¬é–‹æ”¾æ™‚é–“ (visit_time_interval)ã€ç¥¨åƒ¹ (price)ã€å¤šæ´»å‹•åˆ—è¡¨/å‚™è¨» (note) å’Œç›¸é—œç¶²å€ (url)ã€‚

è½‰æ› (Transform)ï¼š

åœ°ç†ç·¨ç¢¼ (_transform_googlegeocoding)ï¼šä½¿ç”¨ Google Maps API å°‡é è¨­åœ°å€ (self.addr) æ­é…å±•è¦½å ´åœ° (item.space) é€²è¡Œåœ°ç†ç·¨ç¢¼ã€‚

æµç¨‹èª¿æ•´ï¼šåœ¨ run_pipeline ä¸­ï¼Œåœ–ç‰‡ä¸‹è¼‰å’Œ OCR è™•ç†è¢«å®‰æ’åœ¨åŸºç¤æå–ä¹‹å¾Œã€AI çµæ§‹åŒ–æå–ä¹‹å‰ï¼Œç¢ºä¿ AI ç²å¾—æœ€å®Œæ•´çš„æ–‡æœ¬è³‡è¨Šã€‚
'''