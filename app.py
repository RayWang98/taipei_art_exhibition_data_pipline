# ===================================================
# streamlit  %% app.py
# ===================================================
import os
import pandas as pd
import streamlit as st # å°å…¥ Streamlit å‡½å¼åº«ï¼Œç”¨æ–¼å»ºæ§‹ Web æ‡‰ç”¨ç¨‹å¼ä»‹é¢
from dotenv import load_dotenv
from rapidfuzz import process # å°å…¥ rapidfuzz å‡½å¼åº«ï¼Œç”¨æ–¼é«˜æ•ˆçš„æ¨¡ç³Šå­—ä¸²åŒ¹é…
from streamlit.components.v1 import html
import datetime as dt
import json
from typing import Dict, List, Tuple # è³‡æ–™æ ¼å¼å®šç¾©
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from matplotlib import font_manager
# å…¶ä»–åŠŸèƒ½ =================================================
from io_database import get_data
from recom_sys import recommendation_engine as rec_sys
# =========================================================


class streamlit_run_app:  
    def __init__(self):
        self.config_ttile = 'å±•è¦½é›·é”ï¼šé›™åŒ—å±•è¦½ç©ºé–“èˆ‡æ–‡åŒ–è¶¨å‹¢åœ°åœ–_Demo'
        self.GOOGLEMAP = os.getenv('GOOGLE_MAPS_API_KEY')
        self.GOOGLEMAPID = os.getenv('GOOGLEMAPID')

        with open('sideprojbrief.txt', 'r', encoding = 'utf-8') as f:
            self.sideprojectbrief = f.read()

        self.topic = r'å±•è¦½é›·é”ï¼šé›™åŒ—å±•è¦½ç©ºé–“èˆ‡æ–‡åŒ–è¶¨å‹¢åœ°åœ–'

        self.venue_urls = dict()
        with open('urls.txt', 'r', encoding = 'utf-8') as f:
            for line in f:
                temp : str = line.strip().replace("'", '')
                parts : List = temp.split(',', 1)
                ven_name = parts[0].strip()
                ven_url = parts[1].strip()
                self.venue_urls[ven_name] = ven_url
            
        self.venue_image_urls = dict()
        with open('urls_image.txt', 'r', encoding = 'utf-8') as f:
            for line in f:
                temp : str = line.strip().replace("'", '')
                parts : List = temp.split(',', 1)
                ven_name = parts[0].strip()
                ven_imgurl = parts[1].strip()
                self.venue_image_urls[ven_name] = ven_imgurl

        self.venue_image_urls_src = dict()
        with open('urls_src.txt', 'r', encoding = 'utf-8') as f:
            for line in f:
                temp : str = line.strip().replace("'", '')
                parts : List = temp.split(',', 1)
                ven_name = parts[0].strip()
                ven_imgsrc = parts[1].strip()
                self.venue_image_urls_src[ven_name] = ven_imgsrc

        self.venue_introduction = dict()
        with open('venue_intro.txt', 'r', encoding = 'utf-8') as f:
            for line in f:
                temp : str = line.strip().replace("'", '')
                parts : List = temp.split(',', 1)
                ven_name = parts[0].strip()
                ven_intro = parts[1].strip()
                self.venue_introduction[ven_name] = ven_intro

        self.venue_hashtags : Dict = dict()
        with open('venue_hashtag.txt', 'r', encoding = 'utf-8') as f:
            for line in f:
                temp : str = line.strip().replace("'", '')
                parts : List = temp.split(',', 1)
                ven_name = parts[0].strip()
                ven_hash = parts[1].strip()
                self.venue_hashtags[ven_name] = ven_hash

        # æ›é åŠæ‰€é¸è³‡è¨Šç´€éŒ„åˆå§‹åŒ–
        if 'page_mode' not in st.session_state:
            st.session_state['page_mode'] = 'home' # é è¨­ç‚ºé¦–é 
        if 'selected' not in st.session_state:
            st.session_state['selected'] = 'None'
        if 'tag_counts' not in st.session_state:
            st.session_state['tag_counts'] = 0

        self.df_exhibitions, self.df_tags, self.df_future_venue = get_data() # è®€å–è³‡æ–™
        self._rec_system = rec_sys() # å–å¾—æ¨è–¦ç³»çµ±æ ¸å¿ƒ

    # def _handle_tag_click(self, ve_name: str, exhibition_id: str):
    #     # å‘¼å«å¼•æ“çš„æ–¹æ³•ä¾†è¨˜éŒ„é»æ“Š
        
    #     # é»æ“Šå¾Œï¼Œè§¸ç™¼ Streamlit é‡æ–°åŸ·è¡Œï¼Œä»¥æ›´æ–°æ¨è–¦é¢æ¿å’Œæœå°‹çµæœ
    #     st.rerun()

    # def _display_tags(self, tags: List[str], exhibition_id: str):
    #     col1, col2 = st.columns([1, 4])
    #     for i, tag in enumerate(tags):
    #         # ä½¿ç”¨ unique key
    #         if col1.button(f'#{tag}', key = f'tag_btn_{exhibition_id}_{i}'):
    #             # é»æ“Šæ™‚å‘¼å«è™•ç†å‡½å¼
    #             self._handle_tag_click(tag, exhibition_id)
     
    def _display_google_map(self, df: pd.DataFrame, venue_name : str, exhibition_name : str, map_height: int = 700) -> None:
        df_v = df[(df['å±•é¤¨åç¨±'] == venue_name) & (df['å±•è¦½åç¨±'] == exhibition_name)]
        if df_v.empty:
            st.warning(f'æ•¸æ“šåº«ä¸­æ‰¾ä¸åˆ°å±¬æ–¼ **{df_v}** çš„å±•è¦½é»ä½ã€‚ç„¡æ³•é¡¯ç¤ºåœ°åœ–ã€‚')
            return 
                
        # æº–å‚™æ•¸æ“šï¼šé¸å– lat, lon, title æ¬„ä½ï¼Œä¸¦è½‰æ›ç‚º JSON æ ¼å¼
        point = df_v[['ç·¯åº¦', 'ç¶“åº¦', 'å±•è¦½åç¨±', 'åœ–ç‰‡é€£çµ', 'å±•è¦½åœ°é»']].to_dict('records')
        point_json = json.dumps(point) # å°‡ Python åˆ—è¡¨è½‰æ›ç‚º JavaScript é™£åˆ—å­—ä¸²

        # è¨ˆç®—åœ°åœ–ä¸­å¿ƒé» (æ‰€æœ‰é»çš„å¹³å‡å€¼)
        center_lat = df_v['ç·¯åº¦'].mean()
        center_lon = df_v['ç¶“åº¦'].mean()

        # Google Maps çš„ HTML å’Œ JavaScript ç¨‹å¼ç¢¼
        try:
            # 1. è®€å–æ¨¡æ¿æª”æ¡ˆ
            with open('google_map_html.html', 'r', encoding='utf-8') as f:
                map_template = f.read()

            # 2. æ›¿æ›æ¨¡æ¿è®Šæ•¸
            map_html = map_template.replace(
                '{point_json}', point_json
            ).replace(
                '{center_lat}', str(center_lat)
            ).replace(
                '{center_lon}', str(center_lon)
            ).replace(
                '{GOOGLEMAP}', str(self.GOOGLEMAP)
            ).replace(
                '{GOOGLEMAPID}', str(self.GOOGLEMAPID)
            )

            # 3. ä½¿ç”¨ Streamlit HTML å…ƒä»¶åµŒå…¥åœ°åœ–  
            html(map_html, height = map_height)

        except FileNotFoundError:
            st.error("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åœ°åœ–æ¨¡æ¿æª”æ¡ˆ 'map_template.html'ã€‚è«‹ç¢ºèªæª”æ¡ˆè·¯å¾‘ã€‚")
        except Exception as e:
            st.error(f'æ¸²æŸ“åœ°åœ–æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}')  

    # ğŸ¯ æ–°å¢å‡½å¼ï¼šä½¿ç”¨ st.columns é¡¯ç¤ºå ´é¤¨ç¶²æ ¼åˆ—è¡¨
    def _display_venue_grid(self, info : pd.DataFrame | dict):
        # å®šç¾©æ¯è¡Œé¡¯ç¤º 4 å€‹æ¬„ä½ (åœ¨å¯¬è¢å¹•ä¸‹)
        columns = st.columns(4) 

        # å»ºç«‹å®¹å™¨
        all_venuesorexhibition = [] # å±•é¤¨åç¨± æˆ– å±•è¦½åç¨±
        image_url_dict = dict() # åœ–ç‰‡é€£çµ
        img_src_dict = dict()
        hashtags_dict = dict() # æ¨™ç±¤
        clicktext = ''
        page_mode = ''

        # æ‰€æœ‰è¦å‘ˆç¾çš„åˆ—è¡¨
        if type(info) == pd.DataFrame:
            src_dict = info[['å±•è¦½åç¨±', 'åœ–ç‰‡é€£çµ', 'å±•è¦½ä»‹ç´¹']].to_dict('records')
            for ids in src_dict:
                all_venuesorexhibition.append(ids.get('å±•è¦½åç¨±'))
                image_url_dict[ids.get('å±•è¦½åç¨±')] = ids.get('åœ–ç‰‡é€£çµ')
                hashtags_dict[ids.get('å±•è¦½åç¨±')] = ids.get('å±•è¦½ä»‹ç´¹')[:100] + '...'
                img_src_dict[ids.get('å±•è¦½åç¨±')] = r'# åœ–ç‰‡ä¾†æº-å®˜ç¶²åœ–ç‰‡'
                clicktext = r':ghost: æŸ¥çœ‹å±•è¦½èªªæ˜'
                page_mode = 'exhibition_view'
                
        else:
            all_venuesorexhibition = list(info.keys()) # é¦–é ç”¨çš„ home
            image_url_dict = self.venue_image_urls
            hashtags_dict = self.venue_hashtags
            clicktext = r'ğŸ“ æŸ¥çœ‹å±•é¤¨ä¸­çš„å±•è¦½'
            page_mode = 'map_view'
            src_dict = self.venue_image_urls_src
            img_src_dict = self.venue_image_urls_src
        
        
        
        for i, v_e_name in enumerate(all_venuesorexhibition):
            with columns[i % 4]:
                image_url = image_url_dict.get(v_e_name)
                hashtags = hashtags_dict.get(v_e_name, '')
                src = img_src_dict.get(v_e_name, '')
                
                # ä½¿ç”¨ Streamlit å…§å»ºçš„å…ƒä»¶ä¾†é¡¯ç¤ºå…§å®¹
                styled_caption = f"""
                <div style="
                    font-size: 18px; 
                    color: #f4a460; 
                    font-weight: bold; 
                    text-align: left; /* è®“æ¨™é¡Œç½®ä¸­ */
                    margin-top: 8px; 
                ">
                    {v_e_name}
                </div>
                """
                # 1. é¡¯ç¤ºå ´é¤¨åœ–ç‰‡
                st.image(
                    image = image_url, 
                    # caption = f'**{v_e_name}**',
                    use_container_width = True, # è®“åœ–ç‰‡å¡«æ»¿æ¬„ä½å¯¬åº¦
                    output_format = 'auto'
                )

                # 2. é¡¯ç¤º å±•é¤¨åç¨±
                st.markdown(styled_caption, unsafe_allow_html = True)

                # 3. é¡¯ç¤º Hashtag åŠ åœ–ç‰‡ä¾†æº
                st.markdown(
                    f'<div style="font-size: 12px; color: #888888; margin-top: -1px;">{hashtags}</div>', 
                    unsafe_allow_html = True
                )
                
                st.markdown(
                    f'<div style="font-size: 10px; color: #888888; margin-top: -1px;">{src}</div>', 
                    unsafe_allow_html = True
                )
                
                # 4. é»æ“ŠæŒ‰éˆ•ï¼Œå¯¦ç¾äº’å‹•
                # ä½¿ç”¨å”¯ä¸€çš„ key ä¾†å€åˆ†æ¯å€‹æŒ‰éˆ•
                button_key = f'select_{v_e_name}'
                               
                # å¦‚æœé»æ“ŠæŒ‰éˆ•ï¼Œå‰‡å°‡å ´é¤¨åç¨±å„²å­˜åˆ° Session State
                if st.button(label = f'**{clicktext}**', key = button_key, use_container_width = True):
                    st.session_state['selected'] = v_e_name
                    st.session_state['page_mode'] = page_mode # è¨­ç½®é é¢æ¨¡å¼ç‚ºåœ°åœ–è¦–åœ–
                    st.rerun() 
                    # Button State Lag æˆ– One-Click Delay ===============================================================================
                    # ç¬¬ä¸€æ¬¡é»æ“Šï¼ŒPython è…³æœ¬å¾é ­åˆ°å°¾åŸ·è¡Œäº†ä¸€æ¬¡ã€‚è®Šæ›´session_state ç‚º **v_e_name**
                    # ç¬¬äºŒæ¬¡é»æ“Šï¼ŒStreamlit åµæ¸¬åˆ° Session State è®ŠåŒ–ï¼Œè§¸ç™¼ç¬¬äºŒæ¬¡é‡æ–°åŸ·è¡Œã€‚
                    # æŒ‰éˆ•é‚è¼¯åŸ·è¡Œå®Œç•¢ä¸¦æˆåŠŸæ›´æ–°äº† Session State æ™‚ï¼Œæ‰‹å‹•å¼·åˆ¶ Streamlit ç«‹å³é‡æ–°åŸ·è¡Œ(st.rerun())ï¼Œè€Œä¸ç­‰å¾… Streamlit è‡ªå‹•è™•ç†ç‹€æ…‹è®ŠåŒ–ã€‚
                    # ===================================================================================================================

        # ç¢ºä¿ selected ç‹€æ…‹å­˜åœ¨
        if 'selected' not in st.session_state:
            st.session_state['selected'] = 'None'
    

    
    # å±•é¤¨ã€å±•è¦½æœå°‹åŠŸèƒ½ =====================================================================
    def _search_fuzzy_wildcard(self, usr_input : str, searchlist : list) -> List[str]:
        choices = [i.lower() for i in searchlist] # è¦æ¯”å°çš„æ¸…å–®
        
        best_match = process.extract(usr_input.lower(), choices, limit = 3) # æ¨¡ç³Šæ¯”å°ï¼Œé¸å‰ä¸‰åå‡ºä¾†ï¼›choicesæ˜¯ç”¨æˆ¶å¯é¸çš„å ´é¤¨åˆ—è¡¨
        # å›å‚³ Tupleï¼š("æœ€ä½³åŒ¹é…å­—ä¸²", åˆ†æ•¸, åœ¨æ¸…å–®ä¸­çš„ index)

        score_threshold = 45 # è¨­å®šåˆ†æ•¸é–€æª»
        filtered_match_name = [i[0] for i in best_match if i[1] >= score_threshold] # æŒ‘å‡ºç¬¦åˆé–€æª»çš„ï¼Œå…¶ä»–ä¸Ÿæ‰

        if filtered_match_name:
            return filtered_match_name
        else:
            return []


    # æ•¸æ“šçµ±è¨ˆå“è³ªåŠŸèƒ½ =======================================================================

    # =======================================================================================
    # æ–‡å­—é›²åŠŸèƒ½ - æš«æ™‚åœæ­¢ 20251206
    # å½±éŸ¿é€Ÿåº¦ï¼Œæ”¾åˆ°Liuçš„Tableauå¹³å°ä¸Šé¢
    # =======================================================================================    
    # def _generate_wordcloud_plot(self, keyword_series : pd.DataFrame) -> None:
    #     # 1. è½‰æ›ç‚ºé »ç‡å­—å…¸ {è©å½™: é »ç‡}
    #     word_freq_dict = pd.Series(
    #         keyword_series['å‡ºç¾æ¬¡æ•¸'].values, 
    #         index = keyword_series['Tag']
    #     ).to_dict()

    #     # 2. å®šç¾©ä¸­æ–‡åœç”¨è©
    #     custom_stopwords = set([
    #         'çš„', 'æ˜¯', 'åœ¨', 'èˆ‡', 'å’Œ', 'å±•', 'è¦½', 'è—è¡“', 'ä½œå“', 'è¨­è¨ˆ', 'æ´»å‹•',
    #         'é€é', 'è§€çœ¾', 'ç³»åˆ—', 'å€‹', 'ç”±', 'æ–¼', 'ç‚º', 'å°‡', 'å¹´', 'ä»£', 'æ—¥', '{', '}', ','
    #     ])
            
    #     try:
    #         # 4. åˆå§‹åŒ– WordCloud ç‰©ä»¶
    #         font_path = 'fonts/NotoSansTC-Regular.ttf' # src/fonts/NotoSansTC-Regular.ttf
    #         wordcloud = WordCloud(
    #             font_path = font_path,
    #             width = 2000, 
    #             height = 600,
    #             background_color = None,
    #             mode = 'RGBA', # è¨­ç½®ç‚º RGBA æ¨¡å¼ä»¥æ”¯æ´é€æ˜åº¦
    #             max_words = 50,
    #             # stopwords = custom_stopwords,
    #             collocations = False,
    #             prefer_horizontal = 0.9,
    #             colormap = 'Paired'
    #         ).generate_from_frequencies(word_freq_dict) # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨ generate_from_frequencies

    #         # 5. ä½¿ç”¨ Matplotlib ç¹ªåœ–
    #         fig, ax = plt.subplots(figsize = (20, 15), facecolor = 'none') # facecolor='none' é€æ˜

    #         # è¨­å®š Matplotlib åœ–è¡¨å’Œè»¸çš„èƒŒæ™¯ç‚ºé€æ˜ (é€æ˜åº¦ alpha = 0)
    #         fig.patch.set_alpha(0)  # åœ–è¡¨å¤–æ¡†
    #         ax.patch.set_alpha(0)   # åœ–è¡¨ç¹ªè£½å€å¡Š

    #         ax.imshow(wordcloud, interpolation ='bilinear')
    #         ax.axis('off')
    #         # ax.set_title('å±•è¦½ç†±é–€é—œéµå­—è¶¨å‹¢ (AI Tagging)', fontsize=16)

    #         # 6. ä½¿ç”¨ Streamlit é¡¯ç¤º Matplotlib åœ–è¡¨
    #         st.pyplot(fig)
    #         plt.close(fig) # é—œé–‰ Matplotlib åœ–å½¢ï¼Œé‡‹æ”¾è¨˜æ†¶é«”

    #     except Exception as e:
    #         st.error(f'âŒ ç”¢ç”Ÿæ–‡å­—é›²å¤±æ•—: {e}')

    # å„sessionçš„é é¢å…§å®¹ ======================================================================
    # Session home
    def _home_session(self) -> None:
        # é é¢åŸºç¤è³‡è¨Š
        
        st.markdown(f'# **:orange[{self.topic}]**')    
        st.markdown('---')
        
        col_title, col_worldcloud = st.columns([3, 2]) # è®“æœå°‹æ¬„ä½ä¸ä½”æ»¿æ•´è¡Œ
        with col_title:
            # with row_h, row_t = st.rows([3, 1])
            st.markdown(f'> ç›®å‰æ—¥æœŸ &ensp; {dt.datetime.today().strftime('%Y-%m-%d')}')
            st.markdown(f'{self.sideprojectbrief}')

            # ç”¨æˆ¶æœå°‹çª—æ ¼
            st.markdown('##### **:red[æƒ³å»å“ªè£¡çœ‹å±•?&emsp;&emsp;ç›´æ¥è¼¸å…¥æ‰¾æ›´å¿«å–”!]**')
            usr_input = st.text_input('æœå°‹å±•é¤¨', label_visibility = 'collapsed')
            filtered_venue_names = self._search_fuzzy_wildcard(usr_input, list(self.venue_image_urls.keys())) #
            
            # æ•´ç† - å±•è¦½çš„ç†±é–€é—œéµå­—
            world_feq = []
            world_cloud_select = self.df_tags['hallname'].isin(filtered_venue_names) if filtered_venue_names else self.df_tags['hallname'].isin(list(self.venue_image_urls.keys()))
            df_tags_keywords = self.df_tags[world_cloud_select].copy(deep = True)
            df_tags_keywords['keywords'] = df_tags_keywords['keywords'].str.replace(r'[{}]', '', regex = True).str.split(',')
            for i in df_tags_keywords['keywords']:
                world_feq.extend(i)
            keyword_counts_series = pd.Series(world_feq, name = 'Tag').value_counts().reset_index(name = 'å‡ºç¾æ¬¡æ•¸').sort_values(by = 'å‡ºç¾æ¬¡æ•¸', ascending = False)
        

        # 20251206æš«åœåŠŸèƒ½ - å½±éŸ¿é€Ÿåº¦ä¸”ç§»å‹•åˆ°Tableauå¹³å°ä¸Šé¢å‘ˆç¾å°±å¥½
        # with col_worldcloud:
        #     st.markdown('### **:yellow[ğŸ”¥ å±•è¦½é—œéµå­—ç†±é–€è¶¨å‹¢(AI Tagging)]**')
        #     if not keyword_counts_series.empty:
        #         self._generate_wordcloud_plot(keyword_counts_series)
        #     else:
        #         st.caption('ï¼ˆå°šç„¡é—œéµå­—è³‡æ–™å¯ä¾›åˆ†æï¼‰')

        st.markdown('---')

        if usr_input and filtered_venue_names != []:
            st.markdown('## ğŸ›ï¸ æ‚¨å¯èƒ½è¦æ‰¾çš„å±•é¤¨')
            st.info(f'**:yellow[ğŸ”¥ å…¨é¤¨å‰10å¤§è¦½ç†±é–€é—œéµå­—ï¼š]** {', '.join(keyword_counts_series['Tag'][:10].values)}')
            filtered_venue_info = {
                name : self.venue_image_urls[name] 
                for name in filtered_venue_names 
                if name in self.venue_image_urls
            } # è½‰æ›æˆdictï¼Œç‚ºäº†è¦å‚³å…¥ç‰ˆé¢å‘ˆç¾çš„å‡½æ•¸ä¸­
            self._display_venue_grid(filtered_venue_info)

            st.markdown('---')
        else:
            if usr_input:
                st.markdown('### æ‰¾ä¸åˆ°è¼¸å…¥çš„å±•è¦½é¤¨è€¶...è«‹é‡æ–°è¼¸å…¥ï¼Œæˆ–æ˜¯å¾ä¸‹é¢åœ–ç‰‡ä¸­æ‰¾æ‰¾çœ‹~')
                self._display_venue_grid(self.venue_image_urls)
            else:
                st.markdown('## ğŸ›ï¸ å±•è¦½å ´é¤¨ä¸€è¦½')
                st.info(f'**:yellow[ğŸ”¥ é›™åŒ—å±•è¦½å‰10å¤§ç†±é–€é—œéµå­—ï¼š]** {', '.join(keyword_counts_series['Tag'][:10].values)}')
                self._display_venue_grid(self.venue_image_urls)
                st.markdown('---')
                
                fut_venlist : List[str] = []
                for _, rows in self.df_future_venue.iterrows():
                    fut_venlist.append(rows['é¤¨å'])
                st.markdown(f'> :wrench: æŒçºŒæ–°å¢ä¸­...&emsp;&emsp;{'ã€'.join(fut_venlist)}')
                
                
        
        
               
    
    # Session map_view
    def _map_view_session(self) -> None:
        # è¿”å›æŒ‰éˆ•
        if st.button('â—€ è¿”å›å ´é¤¨åˆ—è¡¨'):
            st.session_state['page_mode'] = 'home' # åˆ‡æ›å›é¦–é 
            st.rerun() # é‡æ–°åŸ·è¡Œæ‡‰ç”¨ç¨‹å¼ä»¥ç«‹å³åˆ‡æ›é é¢
        
        # é é¢å…§å®¹
        df_current_venue = self.df_exhibitions[self.df_exhibitions['å±•é¤¨åç¨±'] == st.session_state['selected']]
        st.markdown(f'# **:orange[{st.session_state['selected']}]**')
        st.markdown(f'> ç›®å‰æ—¥æœŸ &ensp; {dt.datetime.today().strftime('%Y-%m-%d')}')
        st.markdown(f'**{self.venue_introduction.get(st.session_state['selected'])}**')
        st.markdown(f'å®˜ç¶²é€£çµ : {self.venue_urls.get(st.session_state['selected'])}')
        
        st.markdown('---')

        col_search, col_tag = st.columns([2, 3]) # è®“æœå°‹æ¬„ä½ä¸ä½”æ»¿æ•´è¡Œ

        with col_search:
            st.markdown('##### **:red[æœ‰æ²’æœ‰è¦æœå°‹çš„å±•è¦½?&emsp;&emsp;ç›´æ¥è¼¸å…¥æ‰¾æ›´å¿«å–”!]**')
            usr_input = st.text_input('')
            checklist = self.df_exhibitions[self.df_exhibitions['å±•é¤¨åç¨±'] == st.session_state['selected']]['å±•è¦½åç¨±'].unique().tolist()
        st.markdown('---')


        filtered_exhibition_names = self._search_fuzzy_wildcard(usr_input, checklist) # ç”¨æˆ¶å¯èƒ½å†æ‰¾çš„å±•è¦½æ¸…å–®
        # æ•´ç† - å±•è¦½çš„ç†±é–€é—œéµå­—
        world_feq = []
        world_cloud_select = self.df_tags['title'].isin(filtered_exhibition_names) if filtered_exhibition_names else self.df_tags['title'].isin(checklist)
        df_tags_keywords = self.df_tags[world_cloud_select].copy(deep = True)
        df_tags_keywords['keywords'] = df_tags_keywords['keywords'].str.replace(r'[{}]', '', regex = True).str.split(',')
        for i in df_tags_keywords['keywords']:
            world_feq.extend(i)
        keyword_counts_series = pd.Series(world_feq, name = 'Tag').value_counts().reset_index(name = 'å‡ºç¾æ¬¡æ•¸').sort_values(by = 'å‡ºç¾æ¬¡æ•¸', ascending = False)
        hashtaglist = "`" + "` `".join(keyword_counts_series['Tag'].values) + "`"
        
        if usr_input and filtered_exhibition_names != []:
            df_display = df_current_venue[df_current_venue['å±•è¦½åç¨±'].isin(filtered_exhibition_names)]
            st.markdown(f' **:yellow[ğŸ”¥ å±•è¦½é—œéµå­—ï¼š]** ***{hashtaglist}***')
            self._display_venue_grid(df_display)

        else:

            if usr_input:
                st.markdown('### æ‰¾ä¸åˆ°è¼¸å…¥çš„å±•è¦½é¤¨è€¶...è«‹é‡æ–°è¼¸å…¥ï¼Œæˆ–æ˜¯å¾ä¸‹é¢åœ–ç‰‡ä¸­æ‰¾æ‰¾çœ‹~')
                self._display_venue_grid(df_current_venue)
                
            else:
                st.markdown(f' **:yellow[ğŸ”¥ å±•è¦½é—œéµå­—ï¼š]** ***{hashtaglist}***')
                self._display_venue_grid(df_current_venue)

                


    # Session exhibition_view
    def _exhibition_view_session(self) -> None:
        select_ven = st.session_state['selected'] # å±•è¦½è³‡è¨Š
        self._rec_system.record_click(e_name = select_ven, df = self.df_tags) # è¨˜éŒ„ç•¶ä¸‹é é¢ä¸­çš„æ¨™ç±¤ > å¾Œé¢è¦ç”¨ä¾†æ¨è–¦çš„
        
        st.markdown(f'### ğŸ—ºï¸ **{select_ven}** è³‡è¨Š')        
        
        
        st.markdown(f'{self.df_exhibitions[self.df_exhibitions['å±•è¦½åç¨±'] == select_ven]['ç¶²é é€£çµ'].values[0]}')
        home_button, map_button, _ = st.columns([1, 1, 10])
        with map_button:
            if st.button('â—€ è¿”å›å±•è¦½åˆ—è¡¨'):
                st.session_state['page_mode'] = 'map_view' # åˆ‡æ›å›å±•è¦½æ¸…å–®
                st.session_state['selected'] = self.df_exhibitions[self.df_exhibitions['å±•è¦½åç¨±'] == select_ven]['å±•é¤¨åç¨±'].unique().tolist()[0]
                st.rerun() # é‡æ–°åŸ·è¡Œæ‡‰ç”¨ç¨‹å¼ä»¥ç«‹å³åˆ‡æ›é é¢
        with home_button:
            if st.button('â—€ è¿”å›å ´é¤¨åˆ—è¡¨'):
                st.session_state['page_mode'] = 'home' # åˆ‡æ›å›å±•è¦½æ¸…å–®
                st.rerun()
            
            

        if not self.df_exhibitions.empty:
            select_df = self.df_exhibitions[self.df_exhibitions['å±•è¦½åç¨±'] == select_ven] # ç¯©å‡º
            img_src = select_df['åœ–ç‰‡é€£çµ'].values[0]
            st.markdown('---')
            # æ•´ç† - å±•è¦½çš„ç†±é–€é—œéµå­—
            world_feq = []
            world_cloud_select = self.df_tags['title'].isin([select_ven])
            df_tags_keywords = self.df_tags[world_cloud_select].copy(deep = True)
            df_tags_keywords['keywords'] = df_tags_keywords['keywords'].str.replace(r'[{}]', '', regex = True).str.split(',')
            for i in df_tags_keywords['keywords']:
                world_feq.extend(i)
            keyword_counts_series = pd.Series(world_feq, name = 'Tag').value_counts().reset_index(name = 'å‡ºç¾æ¬¡æ•¸').sort_values(by = 'å‡ºç¾æ¬¡æ•¸', ascending = False)
            hashtaglist = "`" + "` `".join(keyword_counts_series['Tag'].values) + "`"
            st.markdown(f' **:yellow[ğŸ”¥ å±•è¦½é—œéµå­—ï¼š]** ***{hashtaglist}***')

            col_list, col_map = st.columns([2, 3]) # 3/5 å¯¬åº¦çµ¦åœ°åœ–, 2/5 å¯¬åº¦çµ¦æ¸…å–®

            with col_list:
                reclist = self._rec_system.recomlist(df = self.df_tags) # è¨˜éŒ„ç•¶ä¸‹é é¢ä¸­çš„æ¨™ç±¤ > å¾Œé¢è¦ç”¨ä¾†æ¨è–¦çš„
                rec_df = self.df_exhibitions[(self.df_exhibitions['å±•è¦½åç¨±'].isin([row for row in reclist if row not in select_df['å±•è¦½åç¨±'].unique().tolist()]))]

                infotext = []
                
                for loc in ['å±•è¦½åœ°é»', 'å±•è¦½åç¨±', 'é–‹å§‹æ—¥æœŸ', 'çµæŸæ—¥æœŸ', 'åƒè§€æ™‚é–“', 'ç¥¨åƒ¹', 'å±•è¦½ä»‹ç´¹']:
                    infotext.append(f'**:yellow[{loc}]** : {select_df[loc].values[0]}')
                
                st.markdown('\n\n'.join(infotext))
                st.image(image = img_src, caption = f'**{select_df['å±•è¦½åç¨±'].values[0]}**')


            with col_map:
                
                st.markdown(f'### å‘¨é‚Šå±•è¦½åœ°åœ–')
                # self._display_google_map(self.df_exhibitions, venue_name = select_df['å±•é¤¨åç¨±'].values[0], exhibition_name = select_ven ,map_height = 600)
                col_list_1, col_list_2 = st.columns([4, 1])
                with col_list_2:
                    lon = self.df_exhibitions[self.df_exhibitions['å±•è¦½åç¨±'] == select_ven]['ç¶“åº¦'].values[0]
                    lat = self.df_exhibitions[self.df_exhibitions['å±•è¦½åç¨±'] == select_ven]['ç·¯åº¦'].values[0]
                    st.link_button(f'é€£ç·šåˆ°google map', f'https://www.google.com/maps/search/?api=1&query={lat},{lon}')


            st.markdown('---')
            if reclist != None:
                st.markdown('##### :heart: :red[ä¹Ÿè¨±ä½ æœƒæœ‰èˆˆè¶£]')
                self._display_venue_grid(rec_df[:4])
    # å„sessionçš„é é¢å…§å®¹ ======================================================================            

   
    # Streamlit æ‡‰ç”¨ç¨‹å¼ä¸»é«” ====================================================================================
    def website_main(self):
        st.set_page_config(layout = 'wide', page_icon = 'ğŸ“Š', page_title = self.config_ttile) # è¨­å®š Streamlit é é¢æ¨™é¡Œå’Œåœ–ç¤ºï¼Œä¸¦è¨­å®šç‚ºå¯¬æ¨¡å¼å¸ƒå±€
        # ğŸ¯ æ³¨å…¥ CSS ä»¥å›ºå®šåœ–ç‰‡é«˜åº¦
        st.markdown('''
            <style>
                /* èª¿æ•´åœ–ç‰‡å¤§å° */
                .stImage img {
                    height: 250px !important; /* è¨­ç½®æ‚¨å¸Œæœ›çš„å›ºå®šé«˜åº¦ï¼Œä¸¦ä½¿ç”¨ !important æé«˜æ¬Šé‡ */
                    width: 100% !important; /* ç¢ºä¿å¯¬åº¦ä½”æ»¿å®¹å™¨ */
                    object-fit: cover !important; /* ç¢ºä¿åœ–ç‰‡ä¸è®Šå½¢ï¼Œæœƒè£å‰ªå¤šé¤˜éƒ¨åˆ†ï¼Œä¸¦ä½¿ç”¨ !important */
                    border-radius: 8px; /* ç¾åŒ–é‚Šè§’ */
                }
                /* ç‚ºäº†ç¾è§€ï¼Œå¯ä»¥è®“åœ–ç‰‡ä¸Šæ–¹çš„å®¹å™¨ margin æ¶ˆé™¤ä¸€äº› */
                div[data-testid="stImage"] {
                    margin-bottom: 0px; 
                }
                
            </style>
        ''', unsafe_allow_html = True)    

        if st.session_state['page_mode'] == 'home':
            self._home_session()
            
        elif st.session_state['page_mode'] == 'map_view':
            self._map_view_session()
            
        elif st.session_state['page_mode'] == 'exhibition_view':    
            self._exhibition_view_session()

        else:
            st.warning('è³‡æ–™åº«é€£ç·šå¤±æ•—æˆ–æ²’æœ‰æ‰¾åˆ°æ­£åœ¨å±•å‡ºçš„å±•è¦½è³‡æ–™ã€‚è«‹æª¢æŸ¥éŒ¯èª¤è¨Šæ¯å’Œé€£ç·šå­—ä¸²ã€‚')

if __name__ == '__main__':
    load_dotenv() 
    app = streamlit_run_app()
    app.website_main()